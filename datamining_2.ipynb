{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 774,
     "status": "ok",
     "timestamp": 1720345934808,
     "user": {
      "displayName": "Tahmineh Tavakoli",
      "userId": "07574817318217611559"
     },
     "user_tz": -210
    },
    "id": "LnMFwaHzELxh"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-033d1e44cfa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1277,
     "status": "ok",
     "timestamp": 1720346218095,
     "user": {
      "displayName": "Tahmineh Tavakoli",
      "userId": "07574817318217611559"
     },
     "user_tz": -210
    },
    "id": "K1leXXXhcAE3"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1720346247749,
     "user": {
      "displayName": "Tahmineh Tavakoli",
      "userId": "07574817318217611559"
     },
     "user_tz": -210
    },
    "id": "Wqut3xlZkUPW",
    "outputId": "70c42af2-7ab2-4633-b93b-be549249c6cc"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"Unnamed: 0\")\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "print(\"Numerical Columns:\", numerical_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Frequent pattern\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop = df.drop(columns=['Rating', 'Reviews', 'Size', 'Installs',  'Rating Count',\n",
    "       'Minimum Installs', 'Developer Internal ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop['Price'] = pd.cut(df_drop['Price'], bins=[-np.inf, 0.33, 0.66, np.inf], labels=['free', 'cheap', 'expensive'], duplicates=\"drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop=df_drop.drop(columns= [ 'Price', 'Last Updated', 'Current Ver', 'App Id', 'Currency', \n",
    "                               'Developer Id', 'Developer Website', 'Developer Email', 'Privacy Policy',\n",
    "                               'Summary','Developer Address','Android Ver', 'Minimum Android', 'Released','Android version Text',\n",
    "                               'Developer','Version'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df_drop)\n",
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets = apriori(df_encoded, min_support=0.5, use_colnames=True)\n",
    "print(frequent_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\n",
    "print(rules)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.clustring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_drop.columns:\n",
    "    print(col , df_drop[col].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "kmeans_labels = kmeans.fit_predict(df_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical = AgglomerativeClustering(n_clusters=4)\n",
    "hierarchical_labels = hierarchical.fit_predict(df_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PCA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c1e2f5c9ceea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvisualize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Create a scatter plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PCA' is not defined"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "visualize = pca.fit_transform(df_encoded)\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.scatterplot(x=visualize[:, 0], y=visualize[:, 1], hue=kmeans_labels, palette='viridis', s=6)\n",
    "plt.title('K-Means Clustering')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "visualize = pca.fit_transform(df_encoded)\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.scatterplot(x=visualize[:, 0], y=visualize[:, 1], hue=hierarchical_labels, palette='viridis', s=6)\n",
    "plt.title('K-Means Clustering')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "visualize = pca.fit_transform(df_encoded)\n",
    "\n",
    "\n",
    "fig_kmeans = px.scatter_3d(\n",
    "    x=visualize[:, 0], \n",
    "    y=visualize[:, 1], \n",
    "    z=visualize[:, 2], \n",
    "    color=kmeans_labels, \n",
    "    title='K-Means Clustering',\n",
    "    size_max=1,\n",
    "    labels={'x': 'Principal Component 1', 'y': 'Principal Component 2', 'z': 'Principal Component 3'}\n",
    ")\n",
    "\n",
    "fig_kmeans.show()\n",
    "\n",
    "fig_hierarchical = px.scatter_3d(\n",
    "    x=visualize[:, 0], \n",
    "    y=visualize[:, 1], \n",
    "    z=visualize[:, 2], \n",
    "    color=hierarchical_labels, \n",
    "    title='Hierarchical Clustering',\n",
    "    labels={'x': 'Principal Component 1', 'y': 'Principal Component 2', 'z': 'Principal Component 3'}\n",
    ")\n",
    "\n",
    "fig_hierarchical.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.experimental import enable_iterative_imputer  # وارد کردن enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "numeric_columns = ['Rating', 'Reviews', 'Size', 'Installs', 'Price', 'Rating Count', 'Minimum Installs']\n",
    "\n",
    "imputer = IterativeImputer()\n",
    "df[numeric_columns] = imputer.fit_transform(df[numeric_columns])\n",
    "\n",
    "df['Reviews_per_Install'] = df['Reviews'] / df['Installs']\n",
    "df['Price_per_Install'] = df['Price'] / df['Installs']\n",
    "df['log_Reviews'] = np.log1p(df['Reviews'])\n",
    "df['sqrt_Installs'] = np.sqrt(df['Installs'])\n",
    "\n",
    "numeric_columns.extend(['Reviews_per_Install', 'Price_per_Install', 'log_Reviews', 'sqrt_Installs'])\n",
    "df = df[(np.abs(stats.zscore(df[numeric_columns])) < 3).all(axis=1)]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_components = pca.fit_transform(df[numeric_columns])\n",
    "\n",
    "selector = SelectKBest(score_func=f_classif, k=5)\n",
    "selector.fit(df[numeric_columns], df['Rating'])\n",
    "selected_features = df[numeric_columns].columns[selector.get_support()]\n",
    "\n",
    "if 'Rating' not in selected_features:\n",
    "    selected_features = np.append(selected_features, 'Rating')\n",
    "\n",
    "print(\"Selected Features:\", selected_features)\n",
    "\n",
    "correlation_matrix = df[selected_features].corr()\n",
    "plt.figure(figsize=(20, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "\n",
    "target_correlation = correlation_matrix['Rating'].sort_values(ascending=False)\n",
    "print(target_correlation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "numeric_columns = ['Rating', 'Reviews', 'Size', 'Installs', 'Price', 'Rating Count', 'Minimum Installs']\n",
    "scaler = StandardScaler()\n",
    "df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
    "\n",
    "correlation_matrix = df[numeric_columns].corr()\n",
    "plt.figure(figsize=(20, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "\n",
    "target_correlation = correlation_matrix['Rating'].sort_values(ascending=False)\n",
    "print(target_correlation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_mean = df['Rating'].mean()\n",
    "rating_std = df['Rating'].std()\n",
    "\n",
    "def categorize_rating(rating):\n",
    "    if rating > rating_mean + rating_std:\n",
    "        return 'High'\n",
    "    elif rating < rating_mean - rating_std:\n",
    "        return 'Low'\n",
    "    else:\n",
    "        return 'Medium'\n",
    "\n",
    "df['Rating_Category'] = df['Rating'].apply(categorize_rating)\n",
    "\n",
    "X = df[selected_features].drop(columns='Rating')\n",
    "y = df['Rating_Category']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "nb_classifier = GaussianNB()\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "svm_classifier = SVC(random_state=42)\n",
    "\n",
    "classifiers = [\n",
    "    ('Naive Bayes', nb_classifier),\n",
    "    ('Random Forest', rf_classifier),\n",
    "    ('SVM', svm_classifier)\n",
    "]\n",
    "\n",
    "evaluation_metrics = {\n",
    "    'Model': [],\n",
    "    'Accuracy': [],\n",
    "    'F1-Score': [],\n",
    "    'Recall': [],\n",
    "    'Precision': []\n",
    "}\n",
    "\n",
    "for name, classifier in classifiers:\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    evaluation_metrics['Model'].append(name)\n",
    "    evaluation_metrics['Accuracy'].append(accuracy)\n",
    "    evaluation_metrics['F1-Score'].append(f1)\n",
    "    evaluation_metrics['Recall'].append(recall)\n",
    "    evaluation_metrics['Precision'].append(precision)\n",
    "\n",
    "df_metrics = pd.DataFrame(evaluation_metrics)\n",
    "print(df_metrics)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "pelMsTNDYTX6",
    "ukZjXqLcELxp",
    "plOh5GaHYTYK",
    "zcCE59OqYTYL",
    "tcyGkkafYTYM",
    "CzBytjpNYTYO",
    "vu-TNvDIYTYP",
    "FMMoiozkYTYQ",
    "GVNyylRPYTYR",
    "8H0Lyae0YTYR",
    "zaYoyDdYYTYS",
    "CU7rdTP1YTYT"
   ],
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4129951,
     "sourceId": 7152549,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30615,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
